{"task_name": "lab_bench_dbqa:mc", "task_hash": "308f35256ccdd8c1551ae695d06ac367", "task_config": {"task_name": "lab_bench_dbqa:mc", "task_core": "lab_bench_dbqa", "limit": null, "split": "train", "num_shots": 3, "fewshot_seed": 1234, "primary_metric": "acc_raw", "random_subsample_seed": 1234, "context_kwargs": {}, "generation_kwargs": {}, "metric_kwargs": {}, "native_id_field": "id", "fewshot_source": null, "dataset_path": "futurehouse/lab-bench", "dataset_name": "DbQA", "use_chat_format": null, "version": 0, "revision": null, "compute_gold_bpb": false, "external_eval": null, "custom_kwargs": null, "skip_model_judges": null, "model_max_length": null, "metadata": {"description": "LAB-Bench MC: DbQA", "alias": "lab_bench_dbqa:mc"}}, "current_date": "2026-02-03 20:05:44 UTC", "num_instances": 520}